\documentclass{article}
\usepackage{subcaption}
\usepackage{float}

\floatstyle{ruled}
\newfloat{program}{thp}{lop}
\floatname{program}{Program}

\begin{document}

\section*{Single-factor ANOVA with three levels - equal variance at each level}
Data characteristics:
\par\vspace{0.4 cm}
\begin{itemize}
\item Data is classified by three levels of a single factor
\item Error variance is the same at both levels
\end{itemize}

<<>>=
getwd()

data(iris)               #read the (famous) iris data

str(iris)               #show the dataframe structure

y = iris$Sepal.Width    #select the sepal width measurement

boxplot(iris$Sepal.Width~iris$Species)

lvl = as.numeric(iris$Species)  #Stan wants a numeric vector, not an R factor          

L=3                     #this time we have three levels
N=length(y)             #as required by the data block in the Stan model file
@

\subsection*{Classical or Frequentist ANOVA}

<<>>=
aov1 = aov(iris$Sepal.Width~iris$Species)
summary(aov1)
@

The standard ANOVA F test is asking the question: Are the means equal at all levels of the factor?
\par\vspace{0.3 cm}
If the $p$-value for the F test is very small, it suggests that they might not be.  The smaller it is, the more likely the means are to be different.
\par\vspace{0.3 cm}
Unfortunately, a small $p$-value tells us nothing about \textbf{which} means are different, and if the factor has more than two levels, you need to run another test to determine which of the three means are different.
\par\vspace{0.3 cm}
There are many tests that will do this.  All of them rely on approximations and they are not all equally conservative in terms of declaring a difference to be significant.
\par\vspace{0.3 cm}
If this sounds like a gray area, it is.  The problem is that the number of possible pairwise comparisons grows as the square of the number of levels of the factor, and as you do more comparisons the probability of a false positive in one of them increases, and can be much smaller than the nominal probability of a false positive (which is .05 or 1 in 20 for the widely used $p$=.05 cutoff)
\par\vspace{0.3 cm}
One of the simplest and most widely used tests is the Tukey "Honest Significant Differences" test.
\par\vspace{0.3 cm}
All followup tests attempt to preserve a low probability of false positives as the number of comparisons increases.  
\par\vspace{0.3 cm}
The Tukey Honest Significant Differences method does every possible pairwise comparison and presents confidence intervals for each difference and an approximate $p$-value.  
\par\vspace{0.3 cm}
A confidence interval that includes zero or a large $p$-value indicates that the means for that pair of levels may not be significantly different.
\par\vspace{0.3 cm}
<<>>=
TukeyHSD(aov1)
@

Which levels does the Tukey HSD indicate are different for the Iris data?
\par\vspace{0.3 cm}
Finally, we'll examine the fitted values for the model.  There will be only three, and each will be the mean for the corresponding level.
<<>>=
levels(iris$Species)

table(aov1$fitted.values)

print(iris$Species)
print(as.numeric(iris$Species))
@

Now let's look at the coefficients, perparing ourselves first for some confusion:

<<>>=
aov1$coefficients
@

How would you recover the fitted values for setosa, versicolor, and virginicus from these coefficients?


Call STAN
<<>>=
library(rstan)                                #make sure rstan is available
rstan_options(auto_write = TRUE)              #use multiple cores
options(mc.cores = parallel::detectCores())   #if we have them
stanfit<-stan("ANOVA_example_1way_2levels.stan")       #call STAN using defaults
print(stanfit)
@

Compare the point estimates for the \texttt{alpha} parameters to the fitted values from the classical ANOVA.

<<>>=
pd = extract(stanfit)

str(pd)
@

Using the posterior draw, estimate the probability that the sepal width for versicolor (level 2) 
is larger than the sepal width for setosa (level 1).

Hint:  try \texttt{mean(pd\$alpha[,2] > pd\$alpha[,1])}

<<>>=
#
@

Now compute the probability that the sepal width for virginica is larger than the sepal width for versicolor.

<<>>=
#
@

Finally, compute the probability that the sepal width for virginica is larger than the sepal width for versicolor is larger than the sepal width for setosa.

<<>>=
#
@

Now we will use the posterior draw for each species in a generative model to see what sort of data our model would typically produce, and compare it to the actual data.

<<>>=
setosa     = rnorm(length(pd$sigma),pd$alpha[,1],pd$sigma)
versicolor = rnorm(length(pd$sigma),pd$alpha[,2],pd$sigma)
virginica  = rnorm(length(pd$sigma),pd$alpha[,3],pd$sigma)

sepal_width = c(setosa,versicolor,virginica)
species     = as.factor(rep(c(1,2,3),each=4000))
@

This somewhat complicated LaTeX code will render two figures side by side for comparison

\begin{figure}[H]
  \begin{subfigure}{.5\textwidth}
  <<test-a, echo=FALSE, results='asis', fig.width=5, fig.height=5>>=
  boxplot(sepal_width~species)
  @
  \caption{Data generated from posterior draw. \label{fig:test-a}}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
  <<test-b, echo=FALSE, results='asis', fig.width=5, fig.height=5>>=
  boxplot(iris$Sepal.Width~iris$Species)
  @
  \caption{This is the actual data. \label{fig:test-b}}
  \end{subfigure}
\caption{Comparison of gerated data using the posterior draw and actual data. \label{fig:test}}
\end{figure}


\end{document}